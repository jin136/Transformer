{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Sequential,Model,initializers,layers,Input\n",
    "\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, key의 문장 길이)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0) # input equals to zero->하삼각영행렬 생성\n",
    "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 1s 0us/step\n",
      "25000 Training sequences\n",
      "25000 Validation sequences\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.preprocessing.sequence' has no attribute 'pad_sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(x_train), \u001b[39m\"\u001b[39m\u001b[39mTraining sequences\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(x_val), \u001b[39m\"\u001b[39m\u001b[39mValidation sequences\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m x_train \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mpreprocessing\u001b[39m.\u001b[39;49msequence\u001b[39m.\u001b[39;49mpad_sequences(x_train, maxlen\u001b[39m=\u001b[39mmaxlen)\n\u001b[0;32m      7\u001b[0m x_val \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39msequence\u001b[39m.\u001b[39mpad_sequences(x_val, maxlen\u001b[39m=\u001b[39mmaxlen)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.preprocessing.sequence' has no attribute 'pad_sequences'"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model\n",
    "\n",
    "\n",
    "class Multi_Head_Attention(layers.Layer):\n",
    "    \n",
    "    def __init__(self,d_model,num_heads,dropout=0,mask=None):\n",
    "        super(Multi_Head_Attention,self).__init__()\n",
    "        self.d_model=d_model #512\n",
    "        self.num_heads=num_heads #8\n",
    "        self.mask=mask\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.d_k=self.d_model//num_heads\n",
    "        self.dropout=dropout\n",
    "        self.wq = layers.Dense(self.d_model)\n",
    "        self.wk = layers.Dense(self.d_model)\n",
    "        self.wv = layers.Dense(self.d_model)\n",
    "        self.dense = layers.Dense(self.d_model)\n",
    "\n",
    "    def call(self,query,key,value):\n",
    "\n",
    "        def Split_Heads(input):\n",
    "            batch_size=tf.shape(input)[0]\n",
    "            seq_length=tf.shape(input)[1]\n",
    "            a=tf.reshape(input, [batch_size,seq_length, self.num_heads, self.d_k])\n",
    "            output=tf.transpose(a, perm=[0,2,1,3])\n",
    "            return output\n",
    "\n",
    "        def Scaled_Dot_Product_Attnetion(query,key,value):\n",
    "\n",
    "            key_dim=tf.cast(tf.shape(key)[-1],tf.float32)\n",
    "            \n",
    "            query = tf.multiply(query, 1.0 / tf.sqrt(float(key_dim)))\n",
    "            \n",
    "            attention_score=tf.matmul(query,key,transpose_a=False,transpose_b=True)\n",
    "            if self.mask is not None:\n",
    "                attention_score += (self.mask * -1e9)\n",
    "                print(attention_score.shape)\n",
    "\n",
    "            attention_prob=tf.nn.softmax(attention_score,axis=-1)\n",
    "            attention_prob=tf.nn.dropout(attention_prob,self.dropout)\n",
    "            attention_value=tf.matmul(attention_prob,value)\n",
    "            return attention_value # 원문에서는 드랍아웃을 추가해서 Dropout 된거(attention output) 안된거(attention score) 둘다 리턴\n",
    "\n",
    "\n",
    "        batch_size=tf.shape(key)[0]\n",
    "        seq_length=tf.shape(key)[1]\n",
    "   \n",
    "        q: tf.Tensor = self.wq(query)\n",
    "        k: tf.Tensor = self.wk(key)\n",
    "        v: tf.Tensor = self.wv(value)\n",
    "  \n",
    "        query=Split_Heads(q)\n",
    "        key=Split_Heads(k)\n",
    "        value=Split_Heads(v)\n",
    "    \n",
    "        concat_attention=Scaled_Dot_Product_Attnetion(query,key,value)\n",
    "     \n",
    "        concat_attention=tf.transpose(concat_attention,perm=[0,2,1,3])\n",
    "\n",
    "        concat_attention=tf.reshape(concat_attention,shape=(batch_size,seq_length,self.d_model))\n",
    "    \n",
    "        output=self.dense(concat_attention)\n",
    "\n",
    "    \n",
    "        return output\n",
    "\n",
    "class MLP(layers.Layer):\n",
    "    def __init__(self,units,dropout_rate):\n",
    "        self.units=units\n",
    "        self.dropout_rate=dropout_rate\n",
    "        self.dropout=layers.Dropout(self.dropout_rate)\n",
    "        self.mlp1=layers.Dense(units=2*self.units,activation=tf.nn.relu)\n",
    "        self.mlp2=layers.Dense(units=self.units,activation=tf.nn.relu)\n",
    "        super(MLP,self).__init__()\n",
    "\n",
    "    def call(self,input):\n",
    "        x=self.mlp1(input)\n",
    "        x=self.dropout(x)\n",
    "        x=self.mlp2(x)\n",
    "        x=self.dropout(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model,Input\n",
    "#from Modules import *\n",
    "#from Data_Prerposessing import *\n",
    "\n",
    "class Transformer():\n",
    "    def __init__(self,input_size,num_classes,patch_size,projection_dim,transformer_layers,d_model,num_heads,dropout_MHA,dropout_MLP,mask):\n",
    "        self.input_size= input_size\n",
    "        self.num_classes=num_classes\n",
    "        self.image_size=self.input_size[0]\n",
    "        self.patch_size=patch_size\n",
    "        self.num_patches=(self.image_size//self.patch_size)**2\n",
    "        self.projection_dim=projection_dim\n",
    "        self.transformer_layers=transformer_layers\n",
    "        self.MLP_units=[self.projection_dim*2,self.projection_dim]\n",
    "        self.d_model=d_model\n",
    "        self.num_heads=num_heads\n",
    "        self.dropout_MHA=dropout_MHA\n",
    "        self.dropout_MLP=dropout_MLP\n",
    "        self.padding_mask=Input(shape=(1,1,None))\n",
    "        self.look_ahead_mask=Input(shape=(1,None,None))\n",
    "        self.Encoder_Multi_Head_Attention=Multi_Head_Attention(d_model=self.d_model,num_heads=self.num_heads,mask=self.padding_mask)\n",
    "        self.Decoder_Multi_Head_Attention=Multi_Head_Attention(d_model=self.d_model,num_heads=self.num_heads,mask=self.look_ahead_mask)\n",
    "\n",
    "        self.MLP=MLP(units=self.d_model,dropout_rate=self.dropout_MLP)\n",
    "        self.output=layers.Dense(units=self.num_classes)\n",
    "\n",
    "    def Encoder_Block(self,input):\n",
    "\n",
    "        x1=layers.LayerNormalization(epsilon=1e-6)(input)\n",
    "        x1=self.Encoder_Multi_Head_Attention(x1,x1,x1)\n",
    "        x2=layers.Add()([x1,input])\n",
    "        x3=layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        \n",
    "        x3=MLP(x3)\n",
    "        \n",
    "        x4=layers.Add()([x3,x2])\n",
    "        \n",
    "        return x4\n",
    "\n",
    "\n",
    "    def Decoder_Block(self,input,enc_out):\n",
    "        \n",
    "        x=self.Decoder_Multi_Head_Attention(input,input,input)#query,key,value\n",
    "        x=layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x1=layers.Add()([x,input])\n",
    "                \n",
    "        x2=self.Decoder_Multi_Head_Attention(x1,enc_out,enc_out)\n",
    "        x2=layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3=layers.Add()([x1,x2])\n",
    "\n",
    "        x4=MLP(units=self.d_model,dropout_rate=self.dropout_MLP)(x3)\n",
    "        \n",
    "        x4=layers.LayerNormalization(epsilon=1e-6)(x4)\n",
    "        \n",
    "        x4=layers.Add()([x3,x4])\n",
    "        \n",
    "        return x4\n",
    "\n",
    "\n",
    "    def call(self):\n",
    "        # input=Input(shape=(self.input_size))\n",
    "\n",
    "        # x=self.Encoder_Block(x)\n",
    "        # for i in range(self.transformer_layers-1):\n",
    "        #     x=self.Encoder_Block(x)\n",
    "        \n",
    "        # # word embedding 단계\n",
    "\n",
    "        # x=self.Decoder_Block()\n",
    "        \n",
    "\n",
    "        # model=Model(inputs=input,outputs=output)\n",
    "        pass\n",
    "\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Transformer( \n",
    "    input_size=(224,224,3),\n",
    "    num_classes=100,\n",
    "    patch_size=8,\n",
    "    projection_dim=64,\n",
    "    transformer_layers=8,\n",
    "    d_model=64,\n",
    "    num_heads=4,\n",
    "    dropout_MHA=0.1,\n",
    "    dropout_MLP=0.1).call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rate=tf.keras.optimizers.schedules.ExponentialDecay(1e-3, 10000, 0.97, staircase=False, name=None)\n",
    "\n",
    "    \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_rate),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] and In[1] must have compatible batch dimensions: [16,56,56,48] vs. [16,57,48,56] [Op:BatchMatMulV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m a\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mones(shape\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m,\u001b[39m56\u001b[39m,\u001b[39m56\u001b[39m,\u001b[39m48\u001b[39m))\n\u001b[0;32m      2\u001b[0m b\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mones(shape\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m,\u001b[39m57\u001b[39m,\u001b[39m48\u001b[39m,\u001b[39m56\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m c\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39;49mmatmul(a,b)\n\u001b[0;32m      5\u001b[0m c\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\tf_210_py_390\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\tf_210_py_390\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] and In[1] must have compatible batch dimensions: [16,56,56,48] vs. [16,57,48,56] [Op:BatchMatMulV2]"
     ]
    }
   ],
   "source": [
    "a=tf.ones(shape=(16,56,56,48))\n",
    "b=tf.ones(shape=(16,57,48,56))\n",
    "\n",
    "c=tf.matmul(a,b)\n",
    "c.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_210_py_390",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e354fddcd8e05f362b5f6e797eff9ab9958198386d58cfc3a129f5c90614cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
